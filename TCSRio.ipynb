{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZDzm/6BYYi8iGI3Mhe1xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmonikamonika/Tcsrio/blob/main/TCSRio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzrI3UDzdUQh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from random import *\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "HDAUlGyhdnTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#These are the forms in the dataset for quick access from manipulation of the file names on each column. Let's create a dictionary with form and writer mapping.\n",
        "d = {}\n",
        "from subprocess import check_output\n",
        "with open('/content/gdrive/MyDrive/TcsRioInternship/Data/RIO_HandWrittenTextExtraction/FormsIAMSmall.txt') as f:\n",
        "    for line in f:\n",
        "        key = line.split(' ')[0]\n",
        "        writer = line.split(' ')[1]\n",
        "        print(key , \" :: \", writer)\n",
        "        d[key] = writer\n",
        "print(len(d.keys()))"
      ],
      "metadata": {
        "id": "UxnXpbTJdqMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All file-names list and target-writer names list are created.\n",
        "tmp = []\n",
        "target_list = []\n",
        "tempDict = {}\n",
        "tempDict = d.copy()\n",
        "print(tempDict)\n",
        "path_to_files = os.path.join('/content/gdrive/MyDrive/TcsRioInternship/Data/RIO_HandWrittenTextExtraction/DataIAMFormSmall', '*')\n",
        "for filename in sorted(glob.glob(path_to_files)):\n",
        "#     print(filename)\n",
        "    tmp.append(filename)\n",
        "    image_name = filename.split('/')[-1]\n",
        "    #print(image_name)\n",
        "    file, ext = os.path.splitext(image_name)\n",
        "    parts = file.split('-')\n",
        "    form = parts[0] + '-' + parts[1]\n",
        "    #print(\"Form Image :: \", form)\n",
        "    tempDict = d.copy()\n",
        "    for key in d.keys():\n",
        "        print(\"Keys:: \",key , \"  :: Form : \", form)\n",
        "        if key == form:\n",
        "            val = tempDict.get(key)\n",
        "            if val:\n",
        "               #print(\"Form mapped with key :: \", key, \" :: \", str(val))\n",
        "               target_list.append(str(val))\n",
        "               del tempDict[key]\n",
        "    #print(target_list)"
      ],
      "metadata": {
        "id": "sf5gT98_dsfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_files = np.asarray(tmp)\n",
        "img_targets = np.asarray(target_list)\n",
        "#print(img_targets)\n",
        "#print(img_files)\n",
        "print(img_files.shape)\n",
        "print(img_targets.shape)"
      ],
      "metadata": {
        "id": "ghOULXhzdvPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the image data\n",
        "for filename in img_files[:3]:\n",
        "    img=mpimg.imread(filename)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img, cmap ='gray')"
      ],
      "metadata": {
        "id": "6RxLKs5SdxUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisation is done using label encoder. No, categorical data.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(img_targets)\n",
        "encoded_Y = encoder.transform(img_targets)\n",
        "\n",
        "print(img_files[:10], img_targets[:10], encoded_Y[:10])"
      ],
      "metadata": {
        "id": "9xNxNiKTdzMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting of data into training and validation sets for cross validation with 4:1:1 ratio.\n",
        "train_files, rem_files, train_targets, rem_targets = train_test_split(\n",
        "        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n",
        "\n",
        "validation_files, test_files, validation_targets, test_targets = train_test_split(\n",
        "        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n",
        "\n",
        "print(train_files.shape, validation_files.shape, test_files.shape)\n",
        "print(train_targets.shape, validation_targets.shape, test_targets.shape)"
      ],
      "metadata": {
        "id": "C578h3HOd1SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator function for generating random crops from each sentence randomly cropping 113*113 patches from images\n",
        "\n",
        "batch_size = 8\n",
        "num_classes = 7\n",
        "\n",
        "def generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n",
        "    num_samples = len(samples)\n",
        "    from sklearn.utils import shuffle\n",
        "    while 1: # Loop forever so the generator never terminates\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            batch_targets = target_files[offset:offset+batch_size]\n",
        "\n",
        "            images = []\n",
        "            targets = []\n",
        "            for i in range(len(batch_samples)):\n",
        "                batch_sample = batch_samples[i]\n",
        "                batch_target = batch_targets[i]\n",
        "                im = Image.open(batch_sample)\n",
        "                cur_width = im.size[0]\n",
        "                cur_height = im.size[1]\n",
        "\n",
        "                # print(cur_width, cur_height)\n",
        "                height_fac = 113 / cur_height\n",
        "\n",
        "                new_width = int(cur_width * height_fac)\n",
        "                size = new_width, 113\n",
        "\n",
        "                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
        "                now_width = imresize.size[0]\n",
        "                now_height = imresize.size[1]\n",
        "                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
        "\n",
        "                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
        "                               # Pick random x%\n",
        "                pick_num = int(len(avail_x_points)*factor)\n",
        "\n",
        "                # Now pick\n",
        "                random_startx = sample(avail_x_points,  pick_num)\n",
        "\n",
        "                for start in random_startx:\n",
        "                    imcrop = imresize.crop((start, 0, start+113, 113))\n",
        "                    images.append(np.asarray(imcrop))\n",
        "                    targets.append(batch_target)\n",
        "\n",
        "            \n",
        "            X_train = np.array(images)\n",
        "            y_train = np.array(targets)\n",
        "\n",
        "            #reshape X_train for feeding in later\n",
        "            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n",
        "            #convert to float and normalize\n",
        "            X_train = X_train.astype('float32')\n",
        "            X_train /= 255\n",
        "\n",
        "            #One hot encode y\n",
        "            y_train = to_categorical(y_train, num_classes)\n",
        "            yield shuffle(X_train, y_train)\n",
        "            "
      ],
      "metadata": {
        "id": "t4eGDJuHd732"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For training and testing, generator function is called with the intent of making train and test generator data.\n",
        "train_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\n",
        "validation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\n",
        "test_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)"
      ],
      "metadata": {
        "id": "0yI54dAwd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A Keras Model is built. Summary of the model is printed below.\n",
        "def resize_image(image):\n",
        "    import tensorflow as tf\n",
        "    return tf.image.resize(image,[56,56])"
      ],
      "metadata": {
        "id": "0rz-lWnGd-r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to resize image to 64x64\n",
        "row, col, ch = 113, 113, 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))"
      ],
      "metadata": {
        "id": "d9S4LFOyeAgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resise data within the neural network\n",
        "model.add(Lambda(resize_image))  #resize images to allow for easy computation\n",
        "#model.add(Lambda(lambda x: resize_image))"
      ],
      "metadata": {
        "id": "UEPuHzxWeCMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model - Building the model suggested in paper\n",
        "\n",
        "model.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n",
        "\n",
        "model.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n",
        "\n",
        "model.add(Convolution2D(filters=128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, name='dense1'))  #1024\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, name='dense2'))  #1024\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes,name='output'))\n",
        "model.add(Activation('softmax'))  #softmax since output is within 50 classes\n",
        "print(\"Worked till here\")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "nb_epoch = 2\n",
        "samples_per_epoch = 233\n",
        "nb_val_samples = 62"
      ],
      "metadata": {
        "id": "rMjsdbZgeIP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"gdrive/content/gdrive/MyDrive/TcsRioInternship/Data/RIO_HandWrittenTextExtraction/check-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "kF8wPzHpePt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Model fit generator\n",
        " # Older Version history_object = model.fit_generator(train_generator, samples_per_epoch= samples_per_epoch,\n",
        "   #                                   validation_data=validation_generator,\n",
        "    #                                  nb_val_samples=nb_val_samples, nb_epoch=nb_epoch, verbose=1, callbacks=callbacks_list)\n",
        "history_object = model.fit_generator(train_generator, \n",
        "                                     steps_per_epoch=samples_per_epoch,\n",
        "                                      validation_data=validation_generator,\n",
        "                                      validation_steps=nb_val_samples, \n",
        "                                     epochs=nb_epoch, verbose=1,\n",
        "                                     callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "zOHt_t60eQXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/gdrive/MyDrive/TcsRioInternship/Data/HTR_Using_CRNN/Model/check-01-0.0000.hdf5')\n",
        "scores = model.evaluate_generator(test_generator,121) # 121 is the number of test images.\n",
        "print(\"Accuracy = \", scores[1] , \" ::\" , len(scores))"
      ],
      "metadata": {
        "id": "-3_WILGPeSsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Load in test data.\"\"\"\n",
        "\n",
        "images = []\n",
        "for filename in test_files[:50]:\n",
        "     im = Image.open(filename)\n",
        "\n",
        "     cur_width = im.size[0]\n",
        "     cur_height = im.size[1]\n",
        "\n",
        "     print(\"Before Crop:\", cur_width, cur_height)\n",
        "     height_fac = 113 / cur_height\n",
        "\n",
        "     new_width = int(cur_width * height_fac)\n",
        "     size = new_width, 113\n",
        "\n",
        "     imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
        "     now_width = imresize.size[0]\n",
        "     now_height = imresize.size[1]\n",
        "     print(\"After Crop:\", now_width, now_height)\n",
        "#     # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
        "\n",
        "     avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
        "#     # Pick random x%\n",
        "     factor = 0.1\n",
        "     pick_num = int(len(avail_x_points)*factor)\n",
        "     print(\"Pick Number is ::\", pick_num)\n",
        "    \n",
        "     random_startx = sample(avail_x_points,  pick_num)\n",
        "\n",
        "     for start in random_startx:\n",
        "         imcrop = imresize.crop((start, 0, start+113, 113))\n",
        "         images.append(np.asarray(imcrop))\n",
        "         \n",
        "     X_test = np.array(images)\n",
        "    \n",
        "     X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n",
        "#     #convert to float and normalize\n",
        "     X_test = X_test.astype('float32')\n",
        "     X_test /= 255\n",
        "     shuffle(X_test)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "mBzymY85eU-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### Predictions\"\"\"\n",
        "\n",
        "predictions = model.predict(X_test, verbose =1)\n",
        "\n",
        "print(predictions.shape)\n",
        "predicted_writer = []\n",
        "for pred in predictions:\n",
        "     predicted_writer.append(np.argmax(pred))\n",
        "print(len(predicted_writer))"
      ],
      "metadata": {
        "id": "qxT1kLDveXuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### Insights\"\"\"\n",
        "\n",
        "writer_number = 18\n",
        "total_images =10\n",
        "counter = 0\n",
        "for i in range(len(predicted_writer)//10):\n",
        "    # print(\"okay1\" + \" \" +  str(predicted_writer[i]) )\n",
        "     if predicted_writer[i] == writer_number:\n",
        "         image = X_test[i].squeeze()\n",
        "         plt.figure(figsize=(2,2))\n",
        "         plt.imshow(image, cmap ='gray')\n",
        "image = X_test[18].squeeze()\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(image, cmap ='gray')"
      ],
      "metadata": {
        "id": "BnNkW7HNeZr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotgraph(epochs, acc, val_acc):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(epochs, acc, 'b')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "w9nJaEMfecI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}